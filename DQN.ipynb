{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "env._max_episode_steps = 15000\n",
    "input_size = env.observation_space.shape[0]\n",
    "output_size = env.action_space.n\n",
    "\n",
    "dis = 0.99\n",
    "REPLAY_MEMORY = 50000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN :\n",
    "    def __init__(self , session, input_size, output_size , name ='main'):\n",
    "        self.session = session\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.net_name = name\n",
    "        \n",
    "        self._build_network()\n",
    "    \n",
    "    def _build_network(self, h_size=10, l_rate = 1e-1) :\n",
    "        with tf.variable_scope(self.net_name):\n",
    "            self._X = tf.placeholder(tf.float32, [None, self.input_size], name ='input_x')\n",
    "\n",
    "            W1 = tf.get_variable(\"W1\" , shape=[self.input_size, h_size], initializer= tf.contrib.layers.xavier_initializer())\n",
    "            layer1 = tf.nn.tanh(tf.matmul(self._X , W1))\n",
    "\n",
    "            W2 = tf.get_variable(\"W2\" , shape=[h_size, self.output_size], initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "            self._Qpred = tf.matmul(layer1,W2)\n",
    "       \n",
    "        self._Y = tf.placeholder(shape=[None, self.output_size], dtype=tf.float32)\n",
    "        \n",
    "        self._loss = tf.reduce_mean(tf.square(self._Y - self._Qpred))\n",
    "        \n",
    "        self._train = tf.train.AdamOptimizer(learning_rate = l_rate).minimize(self._loss)\n",
    "    \n",
    "    def predict(self, state) :\n",
    "        x = np.reshape(state, [1, self.input_size])\n",
    "        return self.session.run(self._Qpred , feed_dict={self._X : x})\n",
    "    \n",
    "    def update(self, x_stack, y_stack) :\n",
    "        return self.session.run([self._loss , self._train] , feed_dict={self._X : x_stack, self._Y : y_stack})\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_replay_train(DQN , train_batch) :\n",
    "    x_stack = np.empty(0).reshape(0, DQN.input_size)\n",
    "    y_stack = np.empty(0).reshape(0, DQN.output_size)\n",
    "    \n",
    "    for state, action, reward, next_state, done in train_batch :\n",
    "        Q = DQN.predict(state)\n",
    "        \n",
    "        if done :\n",
    "            Q[0, action] = reward\n",
    "        else : \n",
    "            Q[0,action] = reward + dis * np.max(DQN.predict(next_state))\n",
    "            \n",
    "        y_stack = np.vstack([y_stack, Q])\n",
    "        x_stack = np.vstack([x_stack, state])\n",
    "    \n",
    "    return DQN.update(x_stack, y_stack)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bot_play(mainDQN) :\n",
    "    s = env.reset()\n",
    "    reward_sum = 0\n",
    "    while True :\n",
    "        env.render()\n",
    "        a = np.argmax(mainDQN.predict(s))\n",
    "        s, reward, done, _ = env.step(a)\n",
    "        reward_sum += reward\n",
    "        if done :\n",
    "            print(\"Total score : {}\".format(reward_sum))\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() :\n",
    "    max_episodes = 5000\n",
    "    \n",
    "    replay_buffer = deque()\n",
    "    \n",
    "    with tf.Session() as sess :\n",
    "        mainDQN = DQN(sess, input_size , output_size)\n",
    "        tf.global_variables_initializer().run()\n",
    "        \n",
    "        for episode in range(max_episodes) :\n",
    "            e = 1. / ((episode / 10 ) + 1 )\n",
    "            done = False\n",
    "            step_count = 0\n",
    "            state = env.reset()\n",
    "            \n",
    "            \n",
    "            while not done :\n",
    "                if np.random.rand(1) < e :\n",
    "                    action = env.action_space.sample()\n",
    "                else :\n",
    "                    action = np.argmax(mainDQN.predict(state))\n",
    "                \n",
    "                next_state, reward, done, _ = env.step(action)\n",
    "                \n",
    "                if done :\n",
    "                    reward = -100\n",
    "                    \n",
    "                replay_buffer.append((state, action, reward, next_state, done))\n",
    "                if len(replay_buffer) > REPLAY_MEMORY :\n",
    "                    replay_buffer.popleft()\n",
    "                    \n",
    "                state = next_state\n",
    "                step_count += 1\n",
    "                if step_count > 10000 :\n",
    "                    break\n",
    "                \n",
    "            print(\"Episode : {}  steps : {}\".format(episode, step_count))\n",
    "            if step_count > 10000 :\n",
    "                pass\n",
    "                break\n",
    "                \n",
    "            if episode % 10 == 1:\n",
    "                for _ in range(50) :\n",
    "                    minibatch = random.sample(replay_buffer , 10)\n",
    "                    loss, _ = simple_replay_train(mainDQN, minibatch)\n",
    "                print('Loss : ', loss)\n",
    "        bot_play(mainDQN)           \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Hellojinoo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Episode : 0  steps : 68\n",
      "Episode : 1  steps : 50\n",
      "Loss :  6.1584926\n",
      "Episode : 2  steps : 12\n",
      "Episode : 3  steps : 14\n",
      "Episode : 4  steps : 17\n",
      "Episode : 5  steps : 12\n",
      "Episode : 6  steps : 15\n",
      "Episode : 7  steps : 17\n",
      "Episode : 8  steps : 9\n",
      "Episode : 9  steps : 15\n",
      "Episode : 10  steps : 9\n",
      "Episode : 11  steps : 10\n",
      "Loss :  1001.79285\n",
      "Episode : 12  steps : 37\n",
      "Episode : 13  steps : 41\n",
      "Episode : 14  steps : 28\n",
      "Episode : 15  steps : 62\n",
      "Episode : 16  steps : 77\n",
      "Episode : 17  steps : 69\n",
      "Episode : 18  steps : 61\n",
      "Episode : 19  steps : 42\n",
      "Episode : 20  steps : 43\n",
      "Episode : 21  steps : 26\n",
      "Loss :  1.0665042\n",
      "Episode : 22  steps : 9\n",
      "Episode : 23  steps : 16\n",
      "Episode : 24  steps : 9\n",
      "Episode : 25  steps : 14\n",
      "Episode : 26  steps : 12\n",
      "Episode : 27  steps : 9\n",
      "Episode : 28  steps : 9\n",
      "Episode : 29  steps : 8\n",
      "Episode : 30  steps : 11\n",
      "Episode : 31  steps : 10\n",
      "Loss :  2.7822442\n",
      "Episode : 32  steps : 9\n",
      "Episode : 33  steps : 10\n",
      "Episode : 34  steps : 11\n",
      "Episode : 35  steps : 11\n",
      "Episode : 36  steps : 12\n",
      "Episode : 37  steps : 9\n",
      "Episode : 38  steps : 12\n",
      "Episode : 39  steps : 9\n",
      "Episode : 40  steps : 9\n",
      "Episode : 41  steps : 9\n",
      "Loss :  15.441829\n",
      "Episode : 42  steps : 57\n",
      "Episode : 43  steps : 37\n",
      "Episode : 44  steps : 41\n",
      "Episode : 45  steps : 42\n",
      "Episode : 46  steps : 31\n",
      "Episode : 47  steps : 33\n",
      "Episode : 48  steps : 29\n",
      "Episode : 49  steps : 54\n",
      "Episode : 50  steps : 35\n",
      "Episode : 51  steps : 43\n",
      "Loss :  14.668483\n",
      "Episode : 52  steps : 34\n",
      "Episode : 53  steps : 76\n",
      "Episode : 54  steps : 33\n",
      "Episode : 55  steps : 35\n",
      "Episode : 56  steps : 35\n",
      "Episode : 57  steps : 46\n",
      "Episode : 58  steps : 40\n",
      "Episode : 59  steps : 28\n",
      "Episode : 60  steps : 32\n",
      "Episode : 61  steps : 45\n",
      "Loss :  520.0709\n",
      "Episode : 62  steps : 23\n",
      "Episode : 63  steps : 22\n",
      "Episode : 64  steps : 25\n",
      "Episode : 65  steps : 35\n",
      "Episode : 66  steps : 20\n",
      "Episode : 67  steps : 30\n",
      "Episode : 68  steps : 32\n",
      "Episode : 69  steps : 29\n",
      "Episode : 70  steps : 35\n",
      "Episode : 71  steps : 49\n",
      "Loss :  1.7456977\n",
      "Episode : 72  steps : 18\n",
      "Episode : 73  steps : 19\n",
      "Episode : 74  steps : 18\n",
      "Episode : 75  steps : 18\n",
      "Episode : 76  steps : 18\n",
      "Episode : 77  steps : 26\n",
      "Episode : 78  steps : 29\n",
      "Episode : 79  steps : 25\n",
      "Episode : 80  steps : 51\n",
      "Episode : 81  steps : 15\n",
      "Loss :  439.1337\n",
      "Episode : 82  steps : 44\n",
      "Episode : 83  steps : 80\n",
      "Episode : 84  steps : 50\n",
      "Episode : 85  steps : 65\n",
      "Episode : 86  steps : 41\n",
      "Episode : 87  steps : 46\n",
      "Episode : 88  steps : 58\n",
      "Episode : 89  steps : 30\n",
      "Episode : 90  steps : 76\n",
      "Episode : 91  steps : 80\n",
      "Loss :  20.398865\n",
      "Episode : 92  steps : 10\n",
      "Episode : 93  steps : 18\n",
      "Episode : 94  steps : 14\n",
      "Episode : 95  steps : 11\n",
      "Episode : 96  steps : 9\n",
      "Episode : 97  steps : 32\n",
      "Episode : 98  steps : 10\n",
      "Episode : 99  steps : 12\n",
      "Episode : 100  steps : 8\n",
      "Episode : 101  steps : 10\n",
      "Loss :  545.0534\n",
      "Episode : 102  steps : 18\n",
      "Episode : 103  steps : 17\n",
      "Episode : 104  steps : 19\n",
      "Episode : 105  steps : 27\n",
      "Episode : 106  steps : 24\n",
      "Episode : 107  steps : 24\n",
      "Episode : 108  steps : 18\n",
      "Episode : 109  steps : 14\n",
      "Episode : 110  steps : 18\n",
      "Episode : 111  steps : 22\n",
      "Loss :  12.499189\n",
      "Episode : 112  steps : 25\n",
      "Episode : 113  steps : 23\n",
      "Episode : 114  steps : 34\n",
      "Episode : 115  steps : 29\n",
      "Episode : 116  steps : 35\n",
      "Episode : 117  steps : 31\n",
      "Episode : 118  steps : 19\n",
      "Episode : 119  steps : 31\n",
      "Episode : 120  steps : 24\n",
      "Episode : 121  steps : 29\n",
      "Loss :  8.682271\n",
      "Episode : 122  steps : 91\n",
      "Episode : 123  steps : 62\n",
      "Episode : 124  steps : 81\n",
      "Episode : 125  steps : 43\n",
      "Episode : 126  steps : 44\n",
      "Episode : 127  steps : 140\n",
      "Episode : 128  steps : 78\n",
      "Episode : 129  steps : 50\n",
      "Episode : 130  steps : 145\n",
      "Episode : 131  steps : 52\n",
      "Loss :  13.138962\n",
      "Episode : 132  steps : 228\n",
      "Episode : 133  steps : 500\n",
      "Episode : 134  steps : 182\n",
      "Episode : 135  steps : 95\n",
      "Episode : 136  steps : 730\n",
      "Episode : 137  steps : 418\n",
      "Episode : 138  steps : 63\n",
      "Episode : 139  steps : 310\n",
      "Episode : 140  steps : 549\n",
      "Episode : 141  steps : 276\n",
      "Loss :  5.943095\n",
      "Episode : 142  steps : 10\n",
      "Episode : 143  steps : 9\n",
      "Episode : 144  steps : 10\n",
      "Episode : 145  steps : 9\n",
      "Episode : 146  steps : 12\n",
      "Episode : 147  steps : 9\n",
      "Episode : 148  steps : 10\n",
      "Episode : 149  steps : 9\n",
      "Episode : 150  steps : 10\n",
      "Episode : 151  steps : 9\n",
      "Loss :  3.199443\n",
      "Episode : 152  steps : 19\n",
      "Episode : 153  steps : 15\n",
      "Episode : 154  steps : 26\n",
      "Episode : 155  steps : 15\n",
      "Episode : 156  steps : 20\n",
      "Episode : 157  steps : 18\n",
      "Episode : 158  steps : 22\n",
      "Episode : 159  steps : 22\n",
      "Episode : 160  steps : 18\n",
      "Episode : 161  steps : 20\n",
      "Loss :  9.787822\n",
      "Episode : 162  steps : 12\n",
      "Episode : 163  steps : 14\n",
      "Episode : 164  steps : 21\n",
      "Episode : 165  steps : 16\n",
      "Episode : 166  steps : 13\n",
      "Episode : 167  steps : 14\n",
      "Episode : 168  steps : 15\n",
      "Episode : 169  steps : 18\n",
      "Episode : 170  steps : 12\n",
      "Episode : 171  steps : 14\n",
      "Loss :  6.3122606\n",
      "Episode : 172  steps : 14\n",
      "Episode : 173  steps : 16\n",
      "Episode : 174  steps : 20\n",
      "Episode : 175  steps : 23\n",
      "Episode : 176  steps : 15\n",
      "Episode : 177  steps : 19\n",
      "Episode : 178  steps : 17\n",
      "Episode : 179  steps : 22\n",
      "Episode : 180  steps : 18\n",
      "Episode : 181  steps : 14\n",
      "Loss :  512.0738\n",
      "Episode : 182  steps : 15\n",
      "Episode : 183  steps : 14\n",
      "Episode : 184  steps : 12\n",
      "Episode : 185  steps : 16\n",
      "Episode : 186  steps : 19\n",
      "Episode : 187  steps : 14\n",
      "Episode : 188  steps : 21\n",
      "Episode : 189  steps : 19\n",
      "Episode : 190  steps : 17\n",
      "Episode : 191  steps : 12\n",
      "Loss :  519.78455\n",
      "Episode : 192  steps : 13\n",
      "Episode : 193  steps : 9\n",
      "Episode : 194  steps : 13\n",
      "Episode : 195  steps : 13\n",
      "Episode : 196  steps : 9\n",
      "Episode : 197  steps : 16\n",
      "Episode : 198  steps : 11\n",
      "Episode : 199  steps : 13\n",
      "Episode : 200  steps : 12\n",
      "Episode : 201  steps : 11\n",
      "Loss :  640.1809\n",
      "Episode : 202  steps : 46\n",
      "Episode : 203  steps : 44\n",
      "Episode : 204  steps : 50\n",
      "Episode : 205  steps : 48\n",
      "Episode : 206  steps : 31\n",
      "Episode : 207  steps : 38\n",
      "Episode : 208  steps : 28\n",
      "Episode : 209  steps : 47\n",
      "Episode : 210  steps : 54\n",
      "Episode : 211  steps : 67\n",
      "Loss :  10.445527\n",
      "Episode : 212  steps : 21\n",
      "Episode : 213  steps : 38\n",
      "Episode : 214  steps : 22\n",
      "Episode : 215  steps : 22\n",
      "Episode : 216  steps : 25\n",
      "Episode : 217  steps : 22\n",
      "Episode : 218  steps : 42\n",
      "Episode : 219  steps : 26\n",
      "Episode : 220  steps : 32\n",
      "Episode : 221  steps : 50\n",
      "Loss :  10.92468\n",
      "Episode : 222  steps : 28\n",
      "Episode : 223  steps : 42\n",
      "Episode : 224  steps : 29\n",
      "Episode : 225  steps : 43\n",
      "Episode : 226  steps : 54\n",
      "Episode : 227  steps : 65\n",
      "Episode : 228  steps : 69\n",
      "Episode : 229  steps : 229\n",
      "Episode : 230  steps : 44\n",
      "Episode : 231  steps : 55\n",
      "Loss :  3.1430953\n",
      "Episode : 232  steps : 38\n",
      "Episode : 233  steps : 53\n",
      "Episode : 234  steps : 44\n",
      "Episode : 235  steps : 21\n",
      "Episode : 236  steps : 28\n",
      "Episode : 237  steps : 42\n",
      "Episode : 238  steps : 73\n",
      "Episode : 239  steps : 32\n",
      "Episode : 240  steps : 49\n",
      "Episode : 241  steps : 73\n",
      "Loss :  0.8463705\n",
      "Episode : 242  steps : 341\n",
      "Episode : 243  steps : 572\n",
      "Episode : 244  steps : 614\n",
      "Episode : 245  steps : 428\n",
      "Episode : 246  steps : 330\n",
      "Episode : 247  steps : 497\n",
      "Episode : 248  steps : 313\n",
      "Episode : 249  steps : 304\n",
      "Episode : 250  steps : 756\n",
      "Episode : 251  steps : 1628\n",
      "Loss :  3.9138954\n",
      "Episode : 252  steps : 9\n",
      "Episode : 253  steps : 8\n",
      "Episode : 254  steps : 11\n",
      "Episode : 255  steps : 9\n",
      "Episode : 256  steps : 11\n",
      "Episode : 257  steps : 9\n",
      "Episode : 258  steps : 9\n",
      "Episode : 259  steps : 13\n",
      "Episode : 260  steps : 9\n",
      "Episode : 261  steps : 9\n",
      "Loss :  8.552145\n",
      "Episode : 262  steps : 31\n",
      "Episode : 263  steps : 25\n",
      "Episode : 264  steps : 33\n",
      "Episode : 265  steps : 31\n",
      "Episode : 266  steps : 32\n",
      "Episode : 267  steps : 27\n",
      "Episode : 268  steps : 42\n",
      "Episode : 269  steps : 80\n",
      "Episode : 270  steps : 33\n",
      "Episode : 271  steps : 19\n",
      "Loss :  12.090356\n",
      "Episode : 272  steps : 63\n",
      "Episode : 273  steps : 251\n",
      "Episode : 274  steps : 754\n",
      "Episode : 275  steps : 75\n",
      "Episode : 276  steps : 1261\n",
      "Episode : 277  steps : 452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode : 278  steps : 1605\n",
      "Episode : 279  steps : 182\n",
      "Episode : 280  steps : 531\n",
      "Episode : 281  steps : 72\n",
      "Loss :  481.71527\n",
      "Episode : 282  steps : 1560\n",
      "Episode : 283  steps : 647\n",
      "Episode : 284  steps : 57\n",
      "Episode : 285  steps : 412\n",
      "Episode : 286  steps : 752\n",
      "Episode : 287  steps : 1107\n",
      "Episode : 288  steps : 316\n",
      "Episode : 289  steps : 124\n",
      "Episode : 290  steps : 988\n",
      "Episode : 291  steps : 84\n",
      "Loss :  9.868605\n",
      "Episode : 292  steps : 1068\n",
      "Episode : 293  steps : 807\n",
      "Episode : 294  steps : 115\n",
      "Episode : 295  steps : 1152\n",
      "Episode : 296  steps : 184\n",
      "Episode : 297  steps : 95\n",
      "Episode : 298  steps : 561\n",
      "Episode : 299  steps : 89\n",
      "Episode : 300  steps : 1812\n",
      "Episode : 301  steps : 85\n",
      "Loss :  2.2826207\n",
      "Episode : 302  steps : 2017\n",
      "Episode : 303  steps : 2603\n",
      "Episode : 304  steps : 10001\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\" :\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
